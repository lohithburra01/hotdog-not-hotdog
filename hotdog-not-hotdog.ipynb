{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3875822,"sourceType":"datasetVersion","datasetId":2261888}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-21T04:36:30.319557Z","iopub.execute_input":"2024-01-21T04:36:30.320381Z","iopub.status.idle":"2024-01-21T04:36:45.622573Z","shell.execute_reply.started":"2024-01-21T04:36:30.320342Z","shell.execute_reply":"2024-01-21T04:36:45.621342Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dir_hotdog = r\"/kaggle/input/hotdog-nothotdog/hotdog-nothotdog/hotdog-nothotdog/train/hotdog\"\ntrain_dir_nothotdog = r\"/kaggle/input/hotdog-nothotdog/hotdog-nothotdog/hotdog-nothotdog/train/nothotdog\"\ntest_dir_hotdog = r\"/kaggle/input/hotdog-nothotdog/hotdog-nothotdog/hotdog-nothotdog/test/hotdog\"\ntest_dir_nothotdog = r\"/kaggle/input/hotdog-nothotdog/hotdog-nothotdog/hotdog-nothotdog/test/nothotdog\"","metadata":{"execution":{"iopub.status.busy":"2024-01-21T04:36:54.153576Z","iopub.execute_input":"2024-01-21T04:36:54.154397Z","iopub.status.idle":"2024-01-21T04:36:54.161002Z","shell.execute_reply.started":"2024-01-21T04:36:54.154355Z","shell.execute_reply":"2024-01-21T04:36:54.159325Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_width, img_height = 150, 150\nbatch_size = 32\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\ntest_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T04:36:57.215363Z","iopub.execute_input":"2024-01-21T04:36:57.215758Z","iopub.status.idle":"2024-01-21T04:36:57.221629Z","shell.execute_reply.started":"2024-01-21T04:36:57.215730Z","shell.execute_reply":"2024-01-21T04:36:57.220643Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_and_augment_images(directory):\n    images = []\n    labels = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            img_path = os.path.join(root, file)\n            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(img_width, img_height))\n            img_array = tf.keras.preprocessing.image.img_to_array(img)\n            img_array = tf.expand_dims(img_array, 0)\n            images.append(img_array)\n            labels.append(1 if \"hotdog\" in root else 0)\n    return np.vstack(images), np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T04:37:01.746597Z","iopub.execute_input":"2024-01-21T04:37:01.747068Z","iopub.status.idle":"2024-01-21T04:37:01.755932Z","shell.execute_reply.started":"2024-01-21T04:37:01.747022Z","shell.execute_reply":"2024-01-21T04:37:01.754317Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train_hotdog, y_train_hotdog = load_and_augment_images(train_dir_hotdog)\nX_train_nothotdog, y_train_nothotdog = load_and_augment_images(train_dir_nothotdog)\n\nX_train = np.concatenate([X_train_hotdog, X_train_nothotdog])\ny_train = np.concatenate([y_train_hotdog, y_train_nothotdog])\n\nX_test_hotdog, y_test_hotdog = load_and_augment_images(test_dir_hotdog)\nX_test_nothotdog, y_test_nothotdog = load_and_augment_images(test_dir_nothotdog)\n\nX_test = np.concatenate([X_test_hotdog, X_test_nothotdog])\ny_test = np.concatenate([y_test_hotdog, y_test_nothotdog])","metadata":{"execution":{"iopub.status.busy":"2024-01-21T04:37:36.089390Z","iopub.execute_input":"2024-01-21T04:37:36.090416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dropout(0.5))  \nmodel.add(Dense(units=1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n\naccuracy = model.evaluate(X_test, y_test)[1] * 100\nprint(f\"Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}